{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c11a707-53e1-47bc-a9e4-95f1a885ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e701c7-c970-4536-b3f9-7ec48e620e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"cleaned_df_features.pkl\", \"rb\") as f:\n",
    "    df, numerics, curated_cat, other_cat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4e68ed-4ec3-455e-bca3-da4709ce814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 14)\n",
      "(9000, 14)\n",
      "(5000, 14)\n"
     ]
    }
   ],
   "source": [
    "# first we split trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# 10% for testing\n",
    "[df_full_train,df_test] = train_test_split(df,test_size=0.1,random_state=42)\n",
    "# 72% and 18% for train/val\n",
    "[df_train,df_val] = train_test_split(df_full_train,test_size=0.2,random_state=42)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa5ea40-956f-4dfa-9e6c-a129639f83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = df_train.base_passenger_fare.values\n",
    "df_train = df_train.drop(columns=['base_passenger_fare'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a581fb3-4644-44cb-9067-a19ca1845c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import time\n",
    "\n",
    "with open(\"dv_full.pkl\", \"rb\") as f:\n",
    "    dv_full = pickle.load(f)\n",
    "\n",
    "# all features\n",
    "X_full_train = dv_full.transform(df_train.to_dict(orient='records'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cafb70f5-4398-4042-9908-962ec6d414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_val = df_val.base_passenger_fare.values\n",
    "df_val = df_val.drop(columns=['base_passenger_fare'])\n",
    "\n",
    "X_full_val = dv_full.transform(df_val.to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef5835e-5e4f-4627-aa55-28566af23feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trip_miles', 'trip_miles_log1p', 'trip_time', 'trip_time_log1p',\n",
       "       'wait_time_sec_log1p'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftns_full = dv_full.get_feature_names_out()\n",
    "ftns_full[[562,563,564,565,566]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de9f7b3-3096-4b8e-90d5-c0d5a3af63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "||||||| All features |||||||\n",
      "\n",
      "\n",
      "=== Ridge (L2) hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98d052bc331465d9967a227e477a1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ridge alphas:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=  0.0000 | train_RMSE=  7.1372 | val_RMSE=  6.5283 | time= 0.00 min\n",
      "alpha=  0.1000 | train_RMSE=  7.1373 | val_RMSE=  6.5277 | time= 0.00 min\n",
      "alpha=  1.0000 | train_RMSE=  7.1379 | val_RMSE=  6.5243 | time= 0.00 min\n",
      "alpha= 10.0000 | train_RMSE=  7.1442 | val_RMSE=  6.5162 | time= 0.00 min\n",
      "alpha=100.0000 | train_RMSE=  7.1866 | val_RMSE=  6.5077 | time= 0.00 min\n",
      "\n",
      "Best Ridge alpha: 100.0\n",
      "Best Ridge training RMSE: 7.1866\n",
      "Best Ridge validation RMSE: 6.5077\n",
      "Best Ridge training time: 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n||||||| All features |||||||\\n\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Linear models: L2 (Ridge) search\n",
    "# ------------------------------------\n",
    "\n",
    "# Note: with one-hot/sparse features, use with_mean=False\n",
    "# If X_* are sparse, this will keep them sparse where possible.\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [562,563,564,565,566]\n",
    "all_idx = list(range(568))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "ridge_alphas = [0.0, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "print(\"\\n=== Ridge (L2) hyperparameter search ===\")\n",
    "\n",
    "ridge_results = []\n",
    "for alpha in tqdm(ridge_alphas, desc=\"Ridge alphas\"):\n",
    "    model_ridge = Pipeline([\n",
    "        (\"scaler\", preprocess),\n",
    "        (\"reg\", Ridge(alpha=alpha, random_state=0))\n",
    "    ])\n",
    "\n",
    "    t0 = time.time()\n",
    "    model_ridge.fit(X_full_train, y_train)\n",
    "\n",
    "    y_pred = model_ridge.predict(X_full_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "    \n",
    "    y_pred = model_ridge.predict(X_full_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1 - t0\n",
    "\n",
    "    print(f\"alpha={alpha:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "    ridge_results.append((alpha, rmse_train, rmse_val, train_time, model_ridge))\n",
    "\n",
    "# Pick best Ridge by validation RMSE\n",
    "best_ridge_alpha, best_ridge_rmse_train, best_ridge_rmse_val, best_ridge_time, best_ridge_model = min(\n",
    "    ridge_results,\n",
    "    key=lambda x: x[2]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Ridge alpha: {best_ridge_alpha}\")\n",
    "print(f\"Best Ridge training RMSE: {best_ridge_rmse_train:.4f}\")\n",
    "print(f\"Best Ridge validation RMSE: {best_ridge_rmse_val:.4f}\")\n",
    "print(f\"Best Ridge training time: {best_ridge_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d5f5e-250e-4ab2-a369-569b1b5f43e3",
   "metadata": {},
   "source": [
    "Ridge regression on all features achieved XGB's performance on limited features (32% improvement). But still far from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f9fdd0-8044-4269-a940-860db7b567d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "||||||| All features |||||||\n",
      "\n",
      "\n",
      "=== Ridge (L2) hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3276c3f3bb44d93955059cd881d9ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ridge alphas:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=  0.0000 | train_RMSE=  8.6908 | val_RMSE=  8.6861 | time= 0.00 min\n",
      "alpha=  0.1000 | train_RMSE=  8.6908 | val_RMSE=  8.6858 | time= 0.00 min\n",
      "alpha=  1.0000 | train_RMSE=  8.6913 | val_RMSE=  8.6841 | time= 0.00 min\n",
      "alpha= 10.0000 | train_RMSE=  8.6985 | val_RMSE=  8.6776 | time= 0.00 min\n",
      "alpha=100.0000 | train_RMSE=  8.7758 | val_RMSE=  8.7190 | time= 0.00 min\n",
      "\n",
      "Best Ridge alpha: 10.0\n",
      "Best Ridge training RMSE: 8.6985\n",
      "Best Ridge validation RMSE: 8.6776\n",
      "Best Ridge training time: 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n||||||| All features |||||||\\n\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Linear models: L2 (Ridge) search\n",
    "# ------------------------------------\n",
    "\n",
    "# Note: with one-hot/sparse features, use with_mean=False\n",
    "# If X_* are sparse, this will keep them sparse where possible.\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [562,563,564,565,566]\n",
    "all_idx = list(range(568))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "# exclude the non log1p numerics\n",
    "numeric_idx = [563,565,566]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "ridge_alphas = [0.0, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "print(\"\\n=== Ridge (L2) hyperparameter search ===\")\n",
    "\n",
    "ridge_results = []\n",
    "for alpha in tqdm(ridge_alphas, desc=\"Ridge alphas\"):\n",
    "    model_ridge = Pipeline([\n",
    "        (\"scaler\", preprocess),\n",
    "        (\"reg\", Ridge(alpha=alpha, random_state=0))\n",
    "    ])\n",
    "\n",
    "    t0 = time.time()\n",
    "    model_ridge.fit(X_full_train, y_train)\n",
    "\n",
    "    y_pred = model_ridge.predict(X_full_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "    \n",
    "    y_pred = model_ridge.predict(X_full_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1 - t0\n",
    "\n",
    "    print(f\"alpha={alpha:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "    ridge_results.append((alpha, rmse_train, rmse_val, train_time, model_ridge))\n",
    "\n",
    "# Pick best Ridge by validation RMSE\n",
    "best_ridge_alpha, best_ridge_rmse_train, best_ridge_rmse_val, best_ridge_time, best_ridge_model = min(\n",
    "    ridge_results,\n",
    "    key=lambda x: x[2]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Ridge alpha: {best_ridge_alpha}\")\n",
    "print(f\"Best Ridge training RMSE: {best_ridge_rmse_train:.4f}\")\n",
    "print(f\"Best Ridge validation RMSE: {best_ridge_rmse_val:.4f}\")\n",
    "print(f\"Best Ridge training time: {best_ridge_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acb758-2517-47a6-88a6-c4dfde61f101",
   "metadata": {},
   "source": [
    "I realized the first ridge regression contains \"trip_miles\" and \"trip_time\" (in addition to their log1p version).  \n",
    "In the 32% improvement of ridge regression V2 (RMSE=6.72 compared to 10), 22% comes from these two features, and 10% comes from pickup and dropoff location.  \n",
    "This actually makes sense, since they share the skewness as y.  \n",
    "I will keep them for SGD and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92af6c0f-145c-4fd2-bdb7-bf955dcf2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "GridSearchCV done in 0.24 minutes\n",
      "SGDEN Best params: {'reg__alpha': 0.001, 'reg__l1_ratio': 0.5}\n",
      "SGDEN Best CV score (RMSE): 9.151588832521895\n",
      "SGDEN search time: 0.24 minutes\n",
      "SGDEN training RMSE (best model): 9.2400\n",
      "SGDEN validation RMSE (best model): 9.0919\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV version of SGD ElasticNet\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [562,563,564,565,566]\n",
    "all_idx = list(range(568))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "SGDalphas = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "l1_ratios = [0.0, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "model_SGD = Pipeline([\n",
    "    (\"scaler\", preprocess),\n",
    "    (\"reg\", SGDRegressor( \\\n",
    "        loss=\"squared_error\",\n",
    "        penalty=\"elasticnet\",\n",
    "        eta0=1e-5,\n",
    "        max_iter=500,\n",
    "        shuffle=True,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=5,\n",
    "        validation_fraction=0.1,\n",
    "        tol=1e-3,\n",
    "        verbose=0)\n",
    "    )\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"reg__alpha\": SGDalphas,\n",
    "    \"reg__l1_ratio\": l1_ratios,\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=model_SGD,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,               # careful: this is expensive on 14.5M rows\n",
    "    n_jobs=2,           # 1 pipeline at a time; let SGD use threads\n",
    "    verbose=2,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "search.fit(X_full_train, y_train)\n",
    "t1 = time.time()\n",
    "print(f\"GridSearchCV done in {(t1 - t0)/60:.2f} minutes\")\n",
    "\n",
    "\n",
    "print(\"SGDEN Best params:\", search.best_params_)\n",
    "print(\"SGDEN Best CV score (RMSE):\", -search.best_score_)\n",
    "print(f\"SGDEN search time: {(t1 - t0)/60:.2f} minutes\")\n",
    "\n",
    "best_sgd = search.best_estimator_\n",
    "\n",
    "    \n",
    "# Evaluate best XGB on validation set explicitly:\n",
    "y_pred_sgd = best_sgd.predict(X_full_train)\n",
    "sgd_train_rmse = root_mean_squared_error(y_train, y_pred_sgd)\n",
    "\n",
    "y_pred_sgd = best_sgd.predict(X_full_val)\n",
    "sgd_val_rmse = root_mean_squared_error(y_val, y_pred_sgd)\n",
    "print(f\"SGDEN training RMSE (best model): {sgd_train_rmse:.4f}\")\n",
    "print(f\"SGDEN validation RMSE (best model): {sgd_val_rmse:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf12da-a966-48ed-b274-1f54f89a83d7",
   "metadata": {},
   "source": [
    "SGD elastic nest is worse than ridge regression again."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc4c2d33-8e8f-4478-97e4-cd72bd8d6db7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff351cc1-0938-46c3-8d5c-31a0c41e480d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval (early stopping) on 360 rows\n",
      "train (CV tuning) on 713 rows\n",
      "\n",
      "=== XGBoost hyperparameter search ===\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=1.0;, score=-7.876 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=1.0;, score=-7.858 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=1.0;, score=-8.509 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=0.8;, score=-8.185 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=0.8;, score=-8.078 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=0.8;, score=-8.988 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=0.8;, score=-5.973 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=0.8;, score=-7.208 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=0.8;, score=-6.711 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.715 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.548 total time=   0.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-8.372 total time=   0.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-6.339 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-7.142 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-6.849 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=1.0;, score=-6.251 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=1.0;, score=-7.251 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=25, subsample=1.0;, score=-6.223 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.421 total time=   0.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.664 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-5.885 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=0.8;, score=-6.239 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=0.8;, score=-7.314 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=0.8;, score=-6.599 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=11, min_child_weight=50, subsample=1.0;, score=-6.640 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=11, min_child_weight=50, subsample=1.0;, score=-7.385 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=11, min_child_weight=50, subsample=1.0;, score=-7.360 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, min_child_weight=50, subsample=0.8;, score=-6.771 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, min_child_weight=50, subsample=0.8;, score=-7.345 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, min_child_weight=50, subsample=0.8;, score=-7.457 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=8, subsample=0.8;, score=-6.731 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=8, subsample=0.8;, score=-6.773 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=8, subsample=0.8;, score=-5.807 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.866 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.471 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=11, min_child_weight=100, subsample=1.0;, score=-8.315 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=50, subsample=1.0;, score=-6.623 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=50, subsample=1.0;, score=-7.356 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=50, subsample=1.0;, score=-7.261 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.565 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.912 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-5.956 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=50, subsample=1.0;, score=-6.608 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=50, subsample=1.0;, score=-7.392 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=50, subsample=1.0;, score=-7.240 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=0.8;, score=-6.346 total time=   0.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=0.8;, score=-6.729 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=0.8;, score=-5.827 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=25, subsample=0.8;, score=-6.154 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=25, subsample=0.8;, score=-7.506 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=16, min_child_weight=25, subsample=0.8;, score=-6.576 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=100, subsample=0.8;, score=-8.185 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=100, subsample=0.8;, score=-8.078 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=100, subsample=0.8;, score=-8.988 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=1.0;, score=-6.532 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=1.0;, score=-7.483 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=1.0;, score=-7.074 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, min_child_weight=25, subsample=1.0;, score=-6.225 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, min_child_weight=25, subsample=1.0;, score=-7.279 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, min_child_weight=25, subsample=1.0;, score=-6.153 total time=   0.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.553 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.930 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=0.8;, score=-5.997 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=1.0;, score=-6.636 total time=   0.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=1.0;, score=-7.374 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=1.0;, score=-7.357 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.788 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.510 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=16, min_child_weight=100, subsample=1.0;, score=-8.362 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=1.0;, score=-6.383 total time=   0.5s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=1.0;, score=-6.992 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=8, subsample=1.0;, score=-5.990 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.791 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-7.688 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=100, subsample=1.0;, score=-8.529 total time=   0.6s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.469 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.912 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-5.975 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.258 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-7.148 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=8, subsample=1.0;, score=-5.929 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.255 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.732 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=8, subsample=0.8;, score=-5.724 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-6.283 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-6.707 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-5.713 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=1.0;, score=-7.791 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=1.0;, score=-7.688 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=1.0;, score=-8.529 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=0.8;, score=-6.771 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=0.8;, score=-7.387 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=8, min_child_weight=50, subsample=0.8;, score=-7.563 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-6.369 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-6.807 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=1.0;, score=-5.739 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=100, subsample=1.0;, score=-7.665 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=100, subsample=1.0;, score=-7.538 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=100, subsample=1.0;, score=-8.425 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.866 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.471 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-8.315 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=0.8;, score=-6.781 total time=   0.3s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=0.8;, score=-7.244 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=16, min_child_weight=50, subsample=0.8;, score=-7.564 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=8, subsample=0.8;, score=-6.201 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=8, subsample=0.8;, score=-6.727 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=11, min_child_weight=8, subsample=0.8;, score=-5.823 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-6.146 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-7.224 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-6.902 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.329 total time=   0.4s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-6.943 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=1.0;, score=-5.977 total time=   0.6s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=50, subsample=0.8;, score=-6.580 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=50, subsample=0.8;, score=-7.177 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=50, subsample=0.8;, score=-7.499 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.712 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-7.555 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=16, min_child_weight=100, subsample=1.0;, score=-8.377 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=0.8;, score=-7.945 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=0.8;, score=-7.932 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=100, subsample=0.8;, score=-8.809 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=1.0;, score=-6.389 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=1.0;, score=-7.183 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=1.0;, score=-6.129 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=0.8;, score=-6.703 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=0.8;, score=-7.019 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=11, min_child_weight=8, subsample=0.8;, score=-5.971 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-6.159 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-7.169 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=25, subsample=0.8;, score=-6.653 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=0.8;, score=-7.895 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=0.8;, score=-7.961 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=100, subsample=0.8;, score=-8.771 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=1.0;, score=-6.219 total time=   0.0s\n",
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=1.0;, score=-7.466 total time=   0.0s\n",
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, min_child_weight=25, subsample=1.0;, score=-6.191 total time=   0.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-6.111 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-7.111 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, learning_rate=0.05, max_depth=11, min_child_weight=25, subsample=0.8;, score=-6.744 total time=   0.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=0.8;, score=-6.148 total time=   0.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=0.8;, score=-6.701 total time=   0.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=8, subsample=0.8;, score=-5.764 total time=   0.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=100, subsample=0.8;, score=-7.945 total time=   0.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=100, subsample=0.8;, score=-7.932 total time=   0.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=100, subsample=0.8;, score=-8.809 total time=   0.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.423 total time=   0.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=0.8;, score=-6.744 total time=   0.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, min_child_weight=8, subsample=0.8;, score=-5.842 total time=   0.2s\n",
      "XGB Best params: {'subsample': 0.8, 'min_child_weight': 8, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "XGB Best CV score (RMSE): 6.204531477491096\n",
      "XGB search time: 0.60 minutes\n",
      "XGB training RMSE (best model): 7.6259\n",
      "XGB validation RMSE (best model): 7.3949\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. XGBoost: randomized search\n",
    "# -------------------------------\n",
    "\n",
    "# portion out some data from _train for early stopping\n",
    "X_temp, X_stop_xgb, y_temp, y_stop_xgb = train_test_split(\n",
    "    X_full_train, y_train, test_size=0.01, random_state=42)\n",
    "# use fewer data for training for speed\n",
    "X_temp, X_train_xgb, y_temp, y_train_xgb = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.02, random_state=42)\n",
    "\n",
    "print(f\"eval (early stopping) on {y_stop_xgb.shape[0]:d} rows\")\n",
    "print(f\"train (CV tuning) on {y_train_xgb.shape[0]:d} rows\")\n",
    "\n",
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'max_depth': [5,8,11,16],\n",
    "    'learning_rate': [0.3, 0.1, 0.05],\n",
    "    'min_child_weight': [8, 25, 50, 100],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.3, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "# Create XGBClassifier\n",
    "xgb = XGBRegressor(\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,  # if using pandas categorical dtypes\n",
    "    n_estimators=2000,        # large, rely on early stopping\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    \"eval_set\": [(X_stop_xgb, y_stop_xgb)],\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,          # e.g. 50 random trials\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=4,          # shows progress of the search\n",
    "    n_jobs=1,\n",
    "    cv=3   \n",
    ")\n",
    "\n",
    "print(\"\\n=== XGBoost hyperparameter search ===\")\n",
    "t0 = time.time()\n",
    "search.fit(X_train_xgb, y_train_xgb, **fit_params)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Best params:\", search.best_params_)\n",
    "print(\"XGB Best CV score (RMSE):\", -search.best_score_)\n",
    "print(f\"XGB search time: {(t1 - t0)/60:.2f} minutes\")\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "\n",
    "    \n",
    "# Evaluate best XGB on validation set explicitly:\n",
    "y_pred_xgb = best_xgb.predict(X_full_train)\n",
    "xgb_train_rmse = root_mean_squared_error(y_train, y_pred_xgb)\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_full_val)\n",
    "xgb_val_rmse = root_mean_squared_error(y_val, y_pred_xgb)\n",
    "print(f\"XGB training RMSE (best model): {xgb_train_rmse:.4f}\")\n",
    "print(f\"XGB validation RMSE (best model): {xgb_val_rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Summary of model comparison\n",
    "# ------------------------------------\n",
    "\n",
    "#print(\"\\n=== Summary (validation RMSE) ===\")\n",
    "#print(f\"Ridge (L2)   : {best_ridge_rmse:.4f}  (alpha={best_ridge_alpha})\")\n",
    "#print(f\"XGBoost      : {xgb_val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5745bb99-3c84-457b-a207-6f82224a62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    50.000000\n",
      "mean      7.044493\n",
      "std       0.703876\n",
      "min       6.204531\n",
      "25%       6.460469\n",
      "50%       6.751465\n",
      "75%       7.877572\n",
      "max       8.417053\n",
      "Name: mean_CV_RMSE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# let's check the results\n",
    "results = search.cv_results_\n",
    "df_results = pd.DataFrame({\n",
    "    \"mean_fit_time\": results[\"mean_fit_time\"],\n",
    "    \"param_subsample\": results[\"param_subsample\"],\n",
    "    \"param_min_child_weight\": results[\"param_min_child_weight\"],\n",
    "    \"param_max_depth\": results[\"param_max_depth\"],\n",
    "    \"param_learning_rate\": results[\"param_learning_rate\"],\n",
    "    \"param_colsample_bytree\": results[\"param_colsample_bytree\"],\n",
    "    \"mean_CV_RMSE\": -results[\"mean_test_score\"],\n",
    "    \"std_test_score\": results[\"std_test_score\"],\n",
    "    \"rank\": results[\"rank_test_score\"],\n",
    "})\n",
    "\n",
    "df_results.sort_values(\"rank\",inplace=True)\n",
    "print(df_results[\"mean_CV_RMSE\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d41ffbe-756c-4355-949c-3d1dedd45ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>mean_CV_RMSE</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.175050</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.204531</td>\n",
       "      <td>0.384654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.174067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.234218</td>\n",
       "      <td>0.406984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.225880</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.237001</td>\n",
       "      <td>0.411708</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.258309</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.250593</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.419726</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.300675</td>\n",
       "      <td>0.369596</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.203627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.305102</td>\n",
       "      <td>0.438442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.398088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.323062</td>\n",
       "      <td>0.325216</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.352745</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.336359</td>\n",
       "      <td>0.373349</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.523685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.416644</td>\n",
       "      <td>0.399045</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.436916</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.110554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.445074</td>\n",
       "      <td>0.515099</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.272284</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.451904</td>\n",
       "      <td>0.382873</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.548270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.454835</td>\n",
       "      <td>0.412449</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.106836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.477371</td>\n",
       "      <td>0.395217</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.106534</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.493305</td>\n",
       "      <td>0.382890</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.357263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.552015</td>\n",
       "      <td>0.514638</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.128780</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.564477</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.142213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.567200</td>\n",
       "      <td>0.448358</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.230460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.574923</td>\n",
       "      <td>0.478366</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.094239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.625172</td>\n",
       "      <td>0.594377</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.630797</td>\n",
       "      <td>0.507495</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.289979</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.654985</td>\n",
       "      <td>0.412991</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.183651</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.660423</td>\n",
       "      <td>0.412258</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.089118</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.717347</td>\n",
       "      <td>0.446682</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.111133</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.745490</td>\n",
       "      <td>0.564790</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.318694</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.757441</td>\n",
       "      <td>0.452211</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165302</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.776400</td>\n",
       "      <td>0.331638</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.098346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.029947</td>\n",
       "      <td>0.389499</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.337918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.079781</td>\n",
       "      <td>0.339561</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.197183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.080228</td>\n",
       "      <td>0.325709</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.268557</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.085227</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.367437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.122606</td>\n",
       "      <td>0.344099</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.128077</td>\n",
       "      <td>0.345582</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.118630</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.191018</td>\n",
       "      <td>0.300690</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.338762</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.196260</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.106688</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.240055</td>\n",
       "      <td>0.339550</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.283511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.875779</td>\n",
       "      <td>0.391717</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.878169</td>\n",
       "      <td>0.355892</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.126737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.881413</td>\n",
       "      <td>0.356062</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.142678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.884201</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.149866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.884201</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.280835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.886632</td>\n",
       "      <td>0.354852</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.434198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.002647</td>\n",
       "      <td>0.374215</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.438268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.002647</td>\n",
       "      <td>0.374215</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.081066</td>\n",
       "      <td>0.302924</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.090827</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.209218</td>\n",
       "      <td>0.398254</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.306398</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.228566</td>\n",
       "      <td>0.410142</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.307938</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.228566</td>\n",
       "      <td>0.410142</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.103554</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.417053</td>\n",
       "      <td>0.406222</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102758</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.417053</td>\n",
       "      <td>0.406222</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  param_subsample  param_min_child_weight  param_max_depth  \\\n",
       "47       0.175050              0.8                       8                5   \n",
       "28       0.174067              1.0                       8                5   \n",
       "27       0.225880              0.8                       8                8   \n",
       "35       0.258309              0.8                       8               11   \n",
       "15       0.419726              0.8                       8               11   \n",
       "31       0.203627              1.0                       8                5   \n",
       "6        0.398088              1.0                       8                8   \n",
       "49       0.352745              0.8                       8                8   \n",
       "37       0.523685              1.0                       8                8   \n",
       "10       0.121226              0.8                       8               16   \n",
       "26       0.110554              1.0                       8                8   \n",
       "25       0.272284              0.8                       8                8   \n",
       "23       0.548270              1.0                       8               11   \n",
       "13       0.106836              1.0                       8                8   \n",
       "20       0.106534              0.8                       8                8   \n",
       "19       0.357263              1.0                      25                8   \n",
       "42       0.128780              0.8                       8               11   \n",
       "41       0.142213              1.0                       8               11   \n",
       "5        0.230460              1.0                      25               11   \n",
       "45       0.094239              1.0                      25                8   \n",
       "2        0.190206              0.8                      25               11   \n",
       "46       0.289979              0.8                      25               11   \n",
       "43       0.183651              0.8                      25                5   \n",
       "7        0.089118              0.8                      25                8   \n",
       "16       0.111133              0.8                      25               16   \n",
       "36       0.318694              0.8                      25               11   \n",
       "4        0.165302              0.8                      25                5   \n",
       "18       0.098346              1.0                      50                8   \n",
       "14       0.337918              1.0                      50                5   \n",
       "12       0.197183              1.0                      50                5   \n",
       "38       0.268557              0.8                      50                8   \n",
       "21       0.367437              1.0                      50               16   \n",
       "8        0.200654              1.0                      50               11   \n",
       "9        0.118630              0.8                      50                5   \n",
       "34       0.338762              0.8                      50               16   \n",
       "30       0.106688              0.8                      50                8   \n",
       "32       0.283511              1.0                     100                5   \n",
       "3        0.498629              1.0                     100               11   \n",
       "39       0.126737              1.0                     100               16   \n",
       "11       0.142678              1.0                     100               11   \n",
       "33       0.149866              1.0                     100               16   \n",
       "22       0.280835              1.0                     100               16   \n",
       "24       0.434198              1.0                     100               11   \n",
       "29       0.438268              1.0                     100                8   \n",
       "0        0.145419              1.0                     100                5   \n",
       "44       0.090827              0.8                     100                5   \n",
       "40       0.306398              0.8                     100                8   \n",
       "48       0.307938              0.8                     100                5   \n",
       "17       0.103554              0.8                     100                8   \n",
       "1        0.102758              0.8                     100               16   \n",
       "\n",
       "    param_learning_rate  param_colsample_bytree  mean_CV_RMSE  std_test_score  \\\n",
       "47                 0.10                     0.8      6.204531        0.384654   \n",
       "28                 0.10                     0.6      6.234218        0.406984   \n",
       "27                 0.10                     0.8      6.237001        0.411708   \n",
       "35                 0.10                     0.6      6.250593        0.370730   \n",
       "15                 0.05                     0.6      6.300675        0.369596   \n",
       "31                 0.10                     0.3      6.305102        0.438442   \n",
       "6                  0.05                     0.8      6.323062        0.325216   \n",
       "49                 0.05                     0.8      6.336359        0.373349   \n",
       "37                 0.05                     0.3      6.416644        0.399045   \n",
       "10                 0.30                     0.8      6.436916        0.445556   \n",
       "26                 0.30                     0.3      6.445074        0.515099   \n",
       "25                 0.10                     0.3      6.451904        0.382873   \n",
       "23                 0.05                     0.3      6.454835        0.412449   \n",
       "13                 0.30                     0.8      6.477371        0.395217   \n",
       "20                 0.30                     0.6      6.493305        0.382890   \n",
       "19                 0.05                     0.6      6.552015        0.514638   \n",
       "42                 0.30                     0.6      6.564477        0.438902   \n",
       "41                 0.30                     0.3      6.567200        0.448358   \n",
       "5                  0.10                     0.6      6.574923        0.478366   \n",
       "45                 0.30                     0.3      6.625172        0.594377   \n",
       "2                  0.10                     0.3      6.630797        0.507495   \n",
       "46                 0.05                     0.6      6.654985        0.412991   \n",
       "43                 0.10                     0.6      6.660423        0.412258   \n",
       "7                  0.30                     0.6      6.717347        0.446682   \n",
       "16                 0.30                     0.3      6.745490        0.564790   \n",
       "36                 0.05                     0.3      6.757441        0.452211   \n",
       "4                  0.10                     0.8      6.776400        0.331638   \n",
       "18                 0.30                     0.3      7.029947        0.389499   \n",
       "14                 0.05                     0.6      7.079781        0.339561   \n",
       "12                 0.10                     0.6      7.080228        0.325709   \n",
       "38                 0.10                     0.3      7.085227        0.380585   \n",
       "21                 0.05                     0.8      7.122606        0.344099   \n",
       "8                  0.10                     0.8      7.128077        0.345582   \n",
       "9                  0.30                     0.8      7.191018        0.300690   \n",
       "34                 0.05                     0.3      7.196260        0.321678   \n",
       "30                 0.30                     0.8      7.240055        0.339550   \n",
       "32                 0.10                     0.3      7.875779        0.391717   \n",
       "3                  0.05                     0.8      7.878169        0.355892   \n",
       "39                 0.30                     0.6      7.881413        0.356062   \n",
       "11                 0.30                     0.8      7.884201        0.344578   \n",
       "33                 0.30                     0.8      7.884201        0.344578   \n",
       "22                 0.10                     0.8      7.886632        0.354852   \n",
       "24                 0.05                     0.3      8.002647        0.374215   \n",
       "29                 0.05                     0.3      8.002647        0.374215   \n",
       "0                  0.30                     0.3      8.081066        0.302924   \n",
       "44                 0.30                     0.6      8.209218        0.398254   \n",
       "40                 0.05                     0.8      8.228566        0.410142   \n",
       "48                 0.05                     0.8      8.228566        0.410142   \n",
       "17                 0.30                     0.3      8.417053        0.406222   \n",
       "1                  0.30                     0.3      8.417053        0.406222   \n",
       "\n",
       "    rank  \n",
       "47     1  \n",
       "28     2  \n",
       "27     3  \n",
       "35     4  \n",
       "15     5  \n",
       "31     6  \n",
       "6      7  \n",
       "49     8  \n",
       "37     9  \n",
       "10    10  \n",
       "26    11  \n",
       "25    12  \n",
       "23    13  \n",
       "13    14  \n",
       "20    15  \n",
       "19    16  \n",
       "42    17  \n",
       "41    18  \n",
       "5     19  \n",
       "45    20  \n",
       "2     21  \n",
       "46    22  \n",
       "43    23  \n",
       "7     24  \n",
       "16    25  \n",
       "36    26  \n",
       "4     27  \n",
       "18    28  \n",
       "14    29  \n",
       "12    30  \n",
       "38    31  \n",
       "21    32  \n",
       "8     33  \n",
       "9     34  \n",
       "34    35  \n",
       "30    36  \n",
       "32    37  \n",
       "3     38  \n",
       "39    39  \n",
       "11    40  \n",
       "33    40  \n",
       "22    42  \n",
       "24    43  \n",
       "29    43  \n",
       "0     45  \n",
       "44    46  \n",
       "40    47  \n",
       "48    47  \n",
       "17    49  \n",
       "1     49  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad689590-28ec-40f2-a9af-17af920ac438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
