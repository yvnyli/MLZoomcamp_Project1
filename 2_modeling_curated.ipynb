{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07277e32-5cda-4fa3-897d-f36aca4aba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811e293-9953-4f51-b208-281f90168a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"cleaned_df_features.pkl\", \"rb\") as f:\n",
    "    df, numerics, curated_cat, other_cat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab54ee72-a7a0-4a64-a704-3c8d0957bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 14)\n",
      "(9000, 14)\n",
      "(5000, 14)\n"
     ]
    }
   ],
   "source": [
    "# first we split trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# 10% for testing\n",
    "[df_full_train,df_test] = train_test_split(df,test_size=0.1,random_state=42)\n",
    "# 72% and 18% for train/val\n",
    "[df_train,df_val] = train_test_split(df_full_train,test_size=0.2,random_state=42)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca8af29-8568-4897-903b-d51084a66537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get response variable out\n",
    "\n",
    "y_test = df_test.base_passenger_fare.values\n",
    "y_val = df_val.base_passenger_fare.values\n",
    "y_train = df_train.base_passenger_fare.values\n",
    "\n",
    "df_test = df_test.drop(columns=['base_passenger_fare'])\n",
    "df_val = df_val.drop(columns=['base_passenger_fare'])\n",
    "df_train = df_train.drop(columns=['base_passenger_fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b3cbc-3e8f-4a75-ab3a-978aa39af31a",
   "metadata": {},
   "source": [
    "### starting with the curated feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c9fbf8-71cb-4c12-a34e-75523625cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['day_of_week=Friday', 'day_of_week=Monday', 'day_of_week=Saturday',\n",
       "       'day_of_week=Sunday', 'day_of_week=Thursday',\n",
       "       'day_of_week=Tuesday', 'day_of_week=Wednesday', 'hour_of_day=0',\n",
       "       'hour_of_day=1', 'hour_of_day=10', 'hour_of_day=11',\n",
       "       'hour_of_day=12', 'hour_of_day=13', 'hour_of_day=14',\n",
       "       'hour_of_day=15', 'hour_of_day=16', 'hour_of_day=17',\n",
       "       'hour_of_day=18', 'hour_of_day=19', 'hour_of_day=2',\n",
       "       'hour_of_day=20', 'hour_of_day=21', 'hour_of_day=22',\n",
       "       'hour_of_day=23', 'hour_of_day=3', 'hour_of_day=4',\n",
       "       'hour_of_day=5', 'hour_of_day=6', 'hour_of_day=7', 'hour_of_day=8',\n",
       "       'hour_of_day=9', 'hvfhs_license_num=Juno',\n",
       "       'hvfhs_license_num=Lyft', 'hvfhs_license_num=Uber',\n",
       "       'hvfhs_license_num=Via', 'shared_flag_or', 'trip_miles_log1p',\n",
       "       'trip_time_log1p', 'wait_time_sec_log1p', 'wav_request_flag'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding: fit from training set\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import time\n",
    "\n",
    "dv_cur = DictVectorizer(sparse=True)\n",
    "\n",
    "\n",
    "# curated features only\n",
    "X_cur_train = dv_cur.fit_transform(df_train[numerics + curated_cat].to_dict(orient='records'))\n",
    "X_cur_val = dv_cur.transform(df_val[numerics + curated_cat].to_dict(orient='records'))\n",
    "\n",
    "print(X_cur_train.shape)\n",
    "    \n",
    "dv_cur.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ea874f-a94d-4191-8c92-aa8776103216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wait_time_sec_log1p', 'trip_time_log1p', 'trip_miles_log1p'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftns_cur = dv_cur.get_feature_names_out()\n",
    "ftns_cur[[-2,-3,-4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2110ef10-8e9f-4ef5-afa8-f539618886fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "||||||| curated features |||||||\n",
      "\n",
      "\n",
      "=== Ridge (L2) hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116c798106dc49059e786020df7c137b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ridge alphas:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=  0.0000 | train_RMSE=  9.7020 | val_RMSE=  9.6686 | time= 0.00 min\n",
      "alpha=  0.1000 | train_RMSE=  9.7020 | val_RMSE=  9.6686 | time= 0.00 min\n",
      "alpha=  1.0000 | train_RMSE=  9.7020 | val_RMSE=  9.6686 | time= 0.00 min\n",
      "alpha= 10.0000 | train_RMSE=  9.7020 | val_RMSE=  9.6688 | time= 0.00 min\n",
      "alpha=100.0000 | train_RMSE=  9.7031 | val_RMSE=  9.6716 | time= 0.00 min\n",
      "\n",
      "Best Ridge alpha: 0.0\n",
      "Best Ridge training RMSE: 9.7020\n",
      "Best Ridge validation RMSE: 9.6686\n",
      "Best Ridge training time: 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n||||||| curated features |||||||\\n\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Linear models: L2 (Ridge) search\n",
    "# ------------------------------------\n",
    "\n",
    "# Note: with one-hot/sparse features, use with_mean=False\n",
    "# If X_* are sparse, this will keep them sparse where possible.\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [36,37,38]\n",
    "all_idx = list(range(40))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "ridge_alphas = [0.0, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "print(\"\\n=== Ridge (L2) hyperparameter search ===\")\n",
    "\n",
    "ridge_results = []\n",
    "for alpha in tqdm(ridge_alphas, desc=\"Ridge alphas\"):\n",
    "    model_ridge = Pipeline([\n",
    "        (\"scaler\", preprocess),  # safe for sparse\n",
    "        (\"reg\", Ridge(alpha=alpha, random_state=0))\n",
    "    ])\n",
    "\n",
    "    t0 = time.time()\n",
    "    model_ridge.fit(X_cur_train, y_train)\n",
    "\n",
    "    y_pred = model_ridge.predict(X_cur_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "    \n",
    "    y_pred = model_ridge.predict(X_cur_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1 - t0\n",
    "\n",
    "    print(f\"alpha={alpha:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "    ridge_results.append((alpha, rmse_train, rmse_val, train_time, model_ridge))\n",
    "\n",
    "# Pick best Ridge by validation RMSE\n",
    "best_ridge_alpha, best_ridge_rmse_train, best_ridge_rmse_val, best_ridge_time, best_ridge_model = min(\n",
    "    ridge_results,\n",
    "    key=lambda x: x[2]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Ridge alpha: {best_ridge_alpha}\")\n",
    "print(f\"Best Ridge training RMSE: {best_ridge_rmse_train:.4f}\")\n",
    "print(f\"Best Ridge validation RMSE: {best_ridge_rmse_val:.4f}\")\n",
    "print(f\"Best Ridge training time: {best_ridge_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54bd8a27-7052-4854-9b4f-5a389112e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train RMSE: 15.771902985738684\n",
      "Baseline valid RMSE: 16.110006426103364\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_baseline = np.full_like(y_train, np.mean(y_train), dtype=float)\n",
    "y_val_pred_baseline = np.full_like(y_val, np.mean(y_train), dtype=float)\n",
    "\n",
    "print(\"Baseline train RMSE:\", root_mean_squared_error(y_train, y_train_pred_baseline))\n",
    "print(\"Baseline valid RMSE:\", root_mean_squared_error(y_val, y_val_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e4798c-329c-4350-b909-7fed404e9206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ElasticNet hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9010a75f0d8a466d9eeb1f724efa9205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SGD ElasticNet alphas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb67278fa7f442d182d9b1958ce0a281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.000010 | l1r=  0.0000 | train_RMSE= 14.7783 | val_RMSE= 15.0946 | time= 0.00 min\n",
      "alpha=0.000010 | l1r=  0.0500 | train_RMSE= 14.7548 | val_RMSE= 15.0706 | time= 0.00 min\n",
      "alpha=0.000010 | l1r=  0.1000 | train_RMSE= 14.6588 | val_RMSE= 14.9693 | time= 0.00 min\n",
      "alpha=0.000010 | l1r=  0.2000 | train_RMSE= 14.7884 | val_RMSE= 15.1047 | time= 0.00 min\n",
      "alpha=0.000010 | l1r=  0.5000 | train_RMSE= 14.7840 | val_RMSE= 15.1008 | time= 0.00 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c8bb456fad4a2ba008c4b56891a797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.000100 | l1r=  0.0000 | train_RMSE= 14.7243 | val_RMSE= 15.0384 | time= 0.00 min\n",
      "alpha=0.000100 | l1r=  0.0500 | train_RMSE= 14.7486 | val_RMSE= 15.0642 | time= 0.00 min\n",
      "alpha=0.000100 | l1r=  0.1000 | train_RMSE= 14.7128 | val_RMSE= 15.0258 | time= 0.00 min\n",
      "alpha=0.000100 | l1r=  0.2000 | train_RMSE= 14.8089 | val_RMSE= 15.1272 | time= 0.00 min\n",
      "alpha=0.000100 | l1r=  0.5000 | train_RMSE= 14.7540 | val_RMSE= 15.0683 | time= 0.00 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c9955dbb6b41b2a1f3ae2a12b34062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.001000 | l1r=  0.0000 | train_RMSE= 14.7692 | val_RMSE= 15.0847 | time= 0.00 min\n",
      "alpha=0.001000 | l1r=  0.0500 | train_RMSE= 14.7046 | val_RMSE= 15.0173 | time= 0.00 min\n",
      "alpha=0.001000 | l1r=  0.1000 | train_RMSE= 14.7233 | val_RMSE= 15.0375 | time= 0.00 min\n",
      "alpha=0.001000 | l1r=  0.2000 | train_RMSE= 14.6764 | val_RMSE= 14.9881 | time= 0.00 min\n",
      "alpha=0.001000 | l1r=  0.5000 | train_RMSE= 14.7143 | val_RMSE= 15.0274 | time= 0.00 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739446745d1048ebb86ba2d4c7e3c100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.010000 | l1r=  0.0000 | train_RMSE= 14.8155 | val_RMSE= 15.1333 | time= 0.00 min\n",
      "alpha=0.010000 | l1r=  0.0500 | train_RMSE= 14.6835 | val_RMSE= 14.9949 | time= 0.00 min\n",
      "alpha=0.010000 | l1r=  0.1000 | train_RMSE= 14.7271 | val_RMSE= 15.0409 | time= 0.00 min\n",
      "alpha=0.010000 | l1r=  0.2000 | train_RMSE= 14.7739 | val_RMSE= 15.0901 | time= 0.00 min\n",
      "alpha=0.010000 | l1r=  0.5000 | train_RMSE= 14.7189 | val_RMSE= 15.0318 | time= 0.00 min\n",
      "\n",
      "Best SGD alpha: 1e-05\n",
      "Best SGD L1 ratio: 0.1000\n",
      "Best SGD training RMSE: 14.6588\n",
      "Best SGD validation RMSE: 14.9693\n",
      "Best SGD training time: 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [36,37,38]\n",
    "all_idx = list(range(40))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "SGDalphas = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "l1_ratios = [0.0, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "print(\"\\n=== ElasticNet hyperparameter search ===\")\n",
    "SGD_results = []\n",
    "\n",
    "for alpha in tqdm(SGDalphas, desc=\"SGD ElasticNet alphas\"):\n",
    "    for l1r in tqdm(l1_ratios, desc=\"l1 ratio\", leave=False):\n",
    "    \n",
    "        model_SGD = Pipeline([\n",
    "            (\"scaler\", preprocess),\n",
    "            (\"reg\", SGDRegressor( \\\n",
    "                loss=\"squared_error\",\n",
    "                penalty=\"elasticnet\",\n",
    "                alpha=alpha,\n",
    "                l1_ratio=l1r,\n",
    "                eta0=1e-6,\n",
    "                max_iter=100,\n",
    "                shuffle=True,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=5,\n",
    "                validation_fraction=0.1,\n",
    "                tol=1e-3,\n",
    "                verbose=0)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        t0 = time.time()\n",
    "        model_SGD.fit(X_cur_train, y_train)\n",
    "    \n",
    "        y_pred = model_SGD.predict(X_cur_train)\n",
    "        rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "        \n",
    "        y_pred = model_SGD.predict(X_cur_val)\n",
    "        rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        train_time = t1 - t0\n",
    "        \n",
    "        print(f\"alpha={alpha:8.6f} | l1r={l1r:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "        SGD_results.append((alpha, l1r, rmse_train, rmse_val, train_time, model_SGD))\n",
    "\n",
    "\n",
    "best_SGD_alpha, best_SGD_l1r, best_SGD_rmse_train, best_SGD_rmse_val, best_SGD_time, best_SGD_model = min(\n",
    "    SGD_results,\n",
    "    key=lambda x: x[3]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest SGD alpha: {best_SGD_alpha}\")\n",
    "print(f\"Best SGD L1 ratio: {best_SGD_l1r:.4f}\")\n",
    "print(f\"Best SGD training RMSE: {best_SGD_rmse_train:.4f}\")\n",
    "print(f\"Best SGD validation RMSE: {best_SGD_rmse_val:.4f}\")\n",
    "print(f\"Best SGD training time: {best_SGD_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb5c5a-b05c-4d8d-ace8-18a9dd05572d",
   "metadata": {},
   "source": [
    "### summary for Ridge and SGD Elastic Net regression with curated features\n",
    "\n",
    "Ridge trains very fast (<1min) and SGD is a lot slower (a few minutes per model and more hyperparams). \n",
    "\n",
    "Both had similar performances, with ridge being slightly better (RMSE= 9.67 vs 14.88). \n",
    "\n",
    "(This is not what I expected. I think it might be because I did not pick the best hyperparams for SGD and did not let it train for very long.) \n",
    "\n",
    "Both training and validation RMSE are large, although they are better than the baseline model of mean (RMSE=16). \n",
    "\n",
    "Given the median fare is $10, the model is completely underfitting. \n",
    "\n",
    "Maybe the curated features are not informative enough, or the linear regression model is too biased, or maybe RMSE is not a good metric for training because of the skewness of our target variable.\n",
    "\n",
    "In any case, I will try XGBoost next. Hopefully a more flexible model will give us better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ceeddc-e971-4308-9c29-766fd9b9dcd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval (early stopping) on 3600 rows\n",
      "train (CV tuning) on 6480 rows\n",
      "\n",
      "=== XGBoost hyperparameter search ===\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=20, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=20, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=20, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=20, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=20, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=20, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=20, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=20, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, min_child_weight=20, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=10, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=10, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=10, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=5, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=8, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, min_child_weight=5, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=10, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=20, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=20, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, min_child_weight=20, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, min_child_weight=20, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=20, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=20, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, min_child_weight=1, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=5, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, min_child_weight=20, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, min_child_weight=20, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, min_child_weight=20, subsample=0.8; total time=   0.3s\n",
      "XGB Best params: {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n",
      "XGB Best CV score (RMSE): 7.423795554827968\n",
      "XGB search time: 0.69 minutes\n",
      "XGB training RMSE (best model): 6.7223\n",
      "XGB validation RMSE (best model): 6.6622\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. XGBoost: randomized search\n",
    "# -------------------------------\n",
    "\n",
    "# portion out some data from _train for early stopping\n",
    "X_temp, X_stop_xgb, y_temp, y_stop_xgb = train_test_split(\n",
    "    X_cur_train, y_train, test_size=0.1, random_state=42)\n",
    "# use fewer data for training for speed\n",
    "X_temp, X_train_xgb, y_temp, y_train_xgb = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"eval (early stopping) on {y_stop_xgb.shape[0]:d} rows\")\n",
    "print(f\"train (CV tuning) on {y_train_xgb.shape[0]:d} rows\")\n",
    "\n",
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'max_depth': [3,4,5,6,7,8],\n",
    "    'learning_rate': [0.3, 0.2, 0.1, 0.05, 0.01],\n",
    "    'min_child_weight': [1, 5, 10, 20],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create XGBClassifier\n",
    "xgb = XGBRegressor(\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,  # if using pandas categorical dtypes\n",
    "    n_estimators=500,        # large, rely on early stopping\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    \"eval_set\": [(X_stop_xgb, y_stop_xgb)],\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,          # e.g. 50 random trials\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=2,          # shows progress of the search\n",
    "    n_jobs=1,\n",
    "    cv=3   \n",
    ")\n",
    "\n",
    "print(\"\\n=== XGBoost hyperparameter search ===\")\n",
    "t0 = time.time()\n",
    "search.fit(X_train_xgb, y_train_xgb, **fit_params)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Best params:\", search.best_params_)\n",
    "print(\"XGB Best CV score (RMSE):\", -search.best_score_)\n",
    "print(f\"XGB search time: {(t1 - t0)/60:.2f} minutes\")\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "\n",
    "    \n",
    "# Evaluate best XGB on validation set explicitly:\n",
    "y_pred_xgb = best_xgb.predict(X_cur_train)\n",
    "xgb_train_rmse = root_mean_squared_error(y_train, y_pred_xgb)\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_cur_val)\n",
    "xgb_val_rmse = root_mean_squared_error(y_val, y_pred_xgb)\n",
    "print(f\"XGB training RMSE (best model): {xgb_train_rmse:.4f}\")\n",
    "print(f\"XGB validation RMSE (best model): {xgb_val_rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Summary of model comparison\n",
    "# ------------------------------------\n",
    "\n",
    "#print(\"\\n=== Summary (validation RMSE) ===\")\n",
    "#print(f\"Ridge (L2)   : {best_ridge_rmse:.4f}  (alpha={best_ridge_alpha})\")\n",
    "#print(f\"XGBoost      : {xgb_val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e97880-bc20-470e-8b1b-fd930cf7c7db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>mean_CV_RMSE</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.076635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.423796</td>\n",
       "      <td>1.616016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.470099</td>\n",
       "      <td>1.701736</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.471871</td>\n",
       "      <td>1.631738</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.118572</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.506514</td>\n",
       "      <td>1.769289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.145603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.532734</td>\n",
       "      <td>1.660957</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.176727</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.535577</td>\n",
       "      <td>1.667076</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.311408</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.556295</td>\n",
       "      <td>1.636969</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.069810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.570933</td>\n",
       "      <td>1.618129</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.266548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.583824</td>\n",
       "      <td>1.679783</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.590988</td>\n",
       "      <td>1.845288</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.067736</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.592057</td>\n",
       "      <td>1.849559</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.089141</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.594866</td>\n",
       "      <td>1.638221</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.076523</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.603711</td>\n",
       "      <td>1.614152</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.230108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.606472</td>\n",
       "      <td>1.629539</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.210619</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.621480</td>\n",
       "      <td>1.826015</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.881189</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.625697</td>\n",
       "      <td>1.579102</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.892920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.630198</td>\n",
       "      <td>1.614470</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.126640</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.636691</td>\n",
       "      <td>1.659534</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.639660</td>\n",
       "      <td>1.766680</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.001039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.645562</td>\n",
       "      <td>1.732044</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.167876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.646094</td>\n",
       "      <td>1.567487</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.066614</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.654915</td>\n",
       "      <td>1.611413</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.203202</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.655512</td>\n",
       "      <td>1.549614</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.202794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.659035</td>\n",
       "      <td>1.632436</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.332761</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.673218</td>\n",
       "      <td>1.615193</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.240239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.675248</td>\n",
       "      <td>1.616554</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.237317</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.676434</td>\n",
       "      <td>1.766446</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.074876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.676728</td>\n",
       "      <td>1.698848</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.137246</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.678838</td>\n",
       "      <td>1.649303</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.096392</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.695481</td>\n",
       "      <td>1.670741</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.698638</td>\n",
       "      <td>1.632298</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.151837</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.705493</td>\n",
       "      <td>1.635897</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.372389</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.708944</td>\n",
       "      <td>1.658081</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.071758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.712551</td>\n",
       "      <td>1.580281</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.053503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.720270</td>\n",
       "      <td>1.578487</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.049789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.729928</td>\n",
       "      <td>1.628672</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.736071</td>\n",
       "      <td>1.656877</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.082351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.737201</td>\n",
       "      <td>1.559356</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.105560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.740860</td>\n",
       "      <td>1.659477</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.148039</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.783596</td>\n",
       "      <td>1.549406</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.076546</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.787232</td>\n",
       "      <td>1.670717</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053793</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.788867</td>\n",
       "      <td>1.596789</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.064459</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.790022</td>\n",
       "      <td>1.589653</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.793972</td>\n",
       "      <td>1.691649</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.079721</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.795137</td>\n",
       "      <td>1.702291</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.821767</td>\n",
       "      <td>1.703737</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.121721</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.838922</td>\n",
       "      <td>1.588759</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.850888</td>\n",
       "      <td>1.574708</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.091788</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.893224</td>\n",
       "      <td>1.580134</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.081694</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.031789</td>\n",
       "      <td>1.706665</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  param_subsample  param_min_child_weight  param_max_depth  \\\n",
       "42       0.076635              1.0                       1                4   \n",
       "0        0.240340              1.0                       1                7   \n",
       "2        0.142995              1.0                       1                4   \n",
       "23       0.118572              0.6                       1                4   \n",
       "10       0.145603              1.0                       1                7   \n",
       "28       0.176727              0.6                       1                5   \n",
       "43       0.311408              0.8                       1                7   \n",
       "45       0.069810              1.0                       1                3   \n",
       "33       0.266548              1.0                       1                3   \n",
       "29       0.072170              0.6                       1                6   \n",
       "16       0.067736              0.6                       1                5   \n",
       "41       0.089141              0.6                       1                3   \n",
       "30       1.076523              0.6                       5                6   \n",
       "34       0.230108              1.0                      10                3   \n",
       "12       0.210619              0.6                       1                7   \n",
       "6        0.881189              0.6                      20                4   \n",
       "9        0.892920              1.0                      20                4   \n",
       "46       0.126640              0.8                       5                5   \n",
       "3        0.970350              0.6                       5                8   \n",
       "25       1.001039              1.0                      10                6   \n",
       "18       0.167876              1.0                      10                7   \n",
       "26       0.066614              0.8                       1                6   \n",
       "20       0.203202              0.8                      20                8   \n",
       "17       0.202794              1.0                       5                6   \n",
       "49       0.332761              0.8                      20                6   \n",
       "48       0.240239              1.0                       5                5   \n",
       "40       0.237317              0.6                       5                8   \n",
       "36       1.074876              1.0                      20                6   \n",
       "11       1.137246              0.6                      20                8   \n",
       "19       0.096392              0.6                      10                4   \n",
       "4        0.160303              1.0                      20                3   \n",
       "37       0.151837              0.6                      20                4   \n",
       "13       0.372389              0.8                      20                8   \n",
       "21       0.071758              1.0                       5                6   \n",
       "35       0.053503              1.0                      10                3   \n",
       "15       0.049789              1.0                       5                3   \n",
       "47       0.068172              0.6                      10                3   \n",
       "31       0.082351              1.0                       5                7   \n",
       "32       0.105560              1.0                      10                4   \n",
       "14       0.148039              0.8                      20                8   \n",
       "22       0.076546              0.6                       5                6   \n",
       "1        0.053793              0.6                      20                3   \n",
       "7        0.064459              0.6                       1                3   \n",
       "8        0.694715              1.0                       5                4   \n",
       "44       0.079721              0.8                       5                7   \n",
       "27       0.057800              0.6                      10                3   \n",
       "38       0.121721              0.8                      20                7   \n",
       "5        0.081458              0.6                       5                3   \n",
       "24       0.091788              0.8                      20                8   \n",
       "39       0.081694              0.8                       1                7   \n",
       "\n",
       "    param_learning_rate  param_colsample_bytree  mean_CV_RMSE  std_test_score  \\\n",
       "42                 0.20                     0.8      7.423796        1.616016   \n",
       "0                  0.10                     0.6      7.470099        1.701736   \n",
       "2                  0.10                     0.6      7.471871        1.631738   \n",
       "23                 0.10                     1.0      7.506514        1.769289   \n",
       "10                 0.10                     0.8      7.532734        1.660957   \n",
       "28                 0.05                     0.8      7.535577        1.667076   \n",
       "43                 0.05                     0.6      7.556295        1.636969   \n",
       "45                 0.30                     1.0      7.570933        1.618129   \n",
       "33                 0.05                     0.6      7.583824        1.679783   \n",
       "29                 0.20                     1.0      7.590988        1.845288   \n",
       "16                 0.20                     1.0      7.592057        1.849559   \n",
       "41                 0.20                     0.6      7.594866        1.638221   \n",
       "30                 0.01                     0.6      7.603711        1.614152   \n",
       "34                 0.05                     0.8      7.606472        1.629539   \n",
       "12                 0.05                     1.0      7.621480        1.826015   \n",
       "6                  0.01                     0.8      7.625697        1.579102   \n",
       "9                  0.01                     0.8      7.630198        1.614470   \n",
       "46                 0.10                     0.8      7.636691        1.659534   \n",
       "3                  0.01                     1.0      7.639660        1.766680   \n",
       "25                 0.01                     1.0      7.645562        1.732044   \n",
       "18                 0.10                     0.8      7.646094        1.567487   \n",
       "26                 0.30                     0.8      7.654915        1.611413   \n",
       "20                 0.10                     0.8      7.655512        1.549614   \n",
       "17                 0.05                     0.8      7.659035        1.632436   \n",
       "49                 0.05                     0.6      7.673218        1.615193   \n",
       "48                 0.05                     0.6      7.675248        1.616554   \n",
       "40                 0.05                     1.0      7.676434        1.766446   \n",
       "36                 0.01                     1.0      7.676728        1.698848   \n",
       "11                 0.01                     1.0      7.678838        1.649303   \n",
       "19                 0.10                     1.0      7.695481        1.670741   \n",
       "4                  0.10                     0.6      7.698638        1.632298   \n",
       "37                 0.10                     1.0      7.705493        1.635897   \n",
       "13                 0.05                     1.0      7.708944        1.658081   \n",
       "21                 0.20                     0.8      7.712551        1.580281   \n",
       "35                 0.30                     0.8      7.720270        1.578487   \n",
       "15                 0.30                     0.8      7.729928        1.628672   \n",
       "47                 0.20                     1.0      7.736071        1.656877   \n",
       "31                 0.20                     0.8      7.737201        1.559356   \n",
       "32                 0.20                     0.6      7.740860        1.659477   \n",
       "14                 0.20                     0.8      7.783596        1.549406   \n",
       "22                 0.20                     0.8      7.787232        1.670717   \n",
       "1                  0.30                     1.0      7.788867        1.596789   \n",
       "7                  0.30                     0.6      7.790022        1.589653   \n",
       "8                  0.01                     1.0      7.793972        1.691649   \n",
       "44                 0.20                     0.8      7.795137        1.702291   \n",
       "27                 0.30                     1.0      7.821767        1.703737   \n",
       "38                 0.20                     0.6      7.838922        1.588759   \n",
       "5                  0.20                     0.6      7.850888        1.574708   \n",
       "24                 0.30                     0.6      7.893224        1.580134   \n",
       "39                 0.30                     0.6      8.031789        1.706665   \n",
       "\n",
       "    rank  \n",
       "42     1  \n",
       "0      2  \n",
       "2      3  \n",
       "23     4  \n",
       "10     5  \n",
       "28     6  \n",
       "43     7  \n",
       "45     8  \n",
       "33     9  \n",
       "29    10  \n",
       "16    11  \n",
       "41    12  \n",
       "30    13  \n",
       "34    14  \n",
       "12    15  \n",
       "6     16  \n",
       "9     17  \n",
       "46    18  \n",
       "3     19  \n",
       "25    20  \n",
       "18    21  \n",
       "26    22  \n",
       "20    23  \n",
       "17    24  \n",
       "49    25  \n",
       "48    26  \n",
       "40    27  \n",
       "36    28  \n",
       "11    29  \n",
       "19    30  \n",
       "4     31  \n",
       "37    32  \n",
       "13    33  \n",
       "21    34  \n",
       "35    35  \n",
       "15    36  \n",
       "47    37  \n",
       "31    38  \n",
       "32    39  \n",
       "14    40  \n",
       "22    41  \n",
       "1     42  \n",
       "7     43  \n",
       "8     44  \n",
       "44    45  \n",
       "27    46  \n",
       "38    47  \n",
       "5     48  \n",
       "24    49  \n",
       "39    50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the results\n",
    "results = search.cv_results_\n",
    "df_results = pd.DataFrame({\n",
    "    \"mean_fit_time\": results[\"mean_fit_time\"],\n",
    "    \"param_subsample\": results[\"param_subsample\"],\n",
    "    \"param_min_child_weight\": results[\"param_min_child_weight\"],\n",
    "    \"param_max_depth\": results[\"param_max_depth\"],\n",
    "    \"param_learning_rate\": results[\"param_learning_rate\"],\n",
    "    \"param_colsample_bytree\": results[\"param_colsample_bytree\"],\n",
    "    \"mean_CV_RMSE\": -results[\"mean_test_score\"],\n",
    "    \"std_test_score\": results[\"std_test_score\"],\n",
    "    \"rank\": results[\"rank_test_score\"],\n",
    "})\n",
    "\n",
    "df_results.sort_values(\"rank\",inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fdbcca1-3881-4573-b28a-81c0e2be5153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      7.675918\n",
       "std       0.114770\n",
       "min       7.423796\n",
       "25%       7.604401\n",
       "50%       7.674233\n",
       "75%       7.736918\n",
       "max       8.031789\n",
       "Name: mean_CV_RMSE, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[\"mean_CV_RMSE\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114074e-fe8d-4555-bddd-81835411cc84",
   "metadata": {},
   "source": [
    "### summary for XGBoost with curated features\n",
    "XGBoost's RMSE is stuck very closely around $6.5 for both train and val. Hyperparameters make little difference to performance. This suggest underfitting. Because XGBoost is very powerful and flexible, I think the limiting factor is the curated features. It's time to use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c6ec0-cead-4504-875b-c20d1dcc4413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
